# app.py â€” DEMO ì •í™•ë„ = ìƒí’ˆë³„ RÂ²ì˜ íŒë§¤ëŸ‰ ê°€ì¤‘ í‰ê· 
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path

from skops.io import load as skops_load, get_untrusted_types

@st.cache_resource
def _load_hgbr_pipeline(model_path: Path):
    trusted_types = list(get_untrusted_types(file=str(model_path)))
    return skops_load(model_path, trusted=trusted_types)

@st.cache_resource
def _load_catboost_model(model_path: Path):
    from catboost import CatBoostRegressor
    m = CatBoostRegressor()
    m.load_model(str(model_path))
    return m

st.set_page_config(page_title="Randy's Donuts ìˆ˜ìš”ì˜ˆì¸¡ DEMO", layout="wide")

# -----------------------------
# DEMO ê²½ë¡œ / íŒŒì¼ ë§¤í•‘
# -----------------------------
BASE_DIR = Path(r"C:/Users/lalav/OneDrive/ë°”íƒ• í™”ë©´/DEMO")
FILES = {
    "ì œì£¼ì• ì›”ì ": {
        "pos": BASE_DIR / "aewol_POS.csv",
        "pred": BASE_DIR / "aewol_PRED.csv",
        "pred_kind": "HGBR"
    },
    "ë¶€ì‚°ê´‘ì•ˆë¦¬ì ": {
        "pos": BASE_DIR / "gwangan_POS.csv",
        "pred": BASE_DIR / "gwangan_PRED.csv",
        "pred_kind": "CatBoost log1p"
    },
    "ìˆ˜ì›íƒ€ì„ë¹Œë¦¬ì§€ì ": {
        "pos": BASE_DIR / "suwon_POS.csv",
        "pred": BASE_DIR / "suwon_PRED.csv",
        "pred_kind": "CatBoost"
    },
    "ì—°ë‚¨ì ": {
        "pos": BASE_DIR / "yeonnam_POS.csv",
        "pred": BASE_DIR / "yeonnam_PRED.csv",
        "pred_kind": "CatBoost log1p"
    },
}

# -----------------------------
# ìœ í‹¸: ë¡œë”©/ì •ê·œí™”/ì§€í‘œ
# -----------------------------
@st.cache_data
def load_pos(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path)
    # ë‚ ì§œ ì •ê·œí™”
    if "ì¼ì" in df.columns:
        df["ì¼ì"] = pd.to_datetime(df["ì¼ì"])
    elif "ë‚ ì§œ" in df.columns:
        df["ì¼ì"] = pd.to_datetime(df["ë‚ ì§œ"])
    else:
        raise ValueError(f"POS ë‚ ì§œ ì»¬ëŸ¼(ì¼ì/ë‚ ì§œ) ì—†ìŒ: {path}")
    # ìˆ˜ëŸ‰ ì •ê·œí™”
    if "ìˆ˜ëŸ‰" not in df.columns:
        for c in ["íŒë§¤ìˆ˜ëŸ‰", "ì‹¤ì œíŒë§¤", "ì‹¤ì œ", "qty", "QTY"]:
            if c in df.columns:
                df["ìˆ˜ëŸ‰"] = df[c]
                break
        if "ìˆ˜ëŸ‰" not in df.columns:
            raise ValueError(f"POS ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì—†ìŒ: {path}")
    # ìƒí’ˆëª… ë³´ì •
    if "ìƒí’ˆëª…" not in df.columns:
        for c in ["product_name", "ìƒí’ˆ"]:
            if c in df.columns:
                df["ìƒí’ˆëª…"] = df[c]
                break
    return df

def _looks_log_scale(df: pd.DataFrame, store_name: str) -> bool:
    header = " ".join(map(str, df.columns)).lower()
    return ("log" in header) or ("log1p" in header) or ("ì—°ë‚¨" in store_name and "log" in header)

@st.cache_data
def load_pred(path: Path, store_name: str = "", model_name: str = "") -> pd.DataFrame:
    df = pd.read_csv(path)
    # ë‚ ì§œ ì •ê·œí™”
    if "ë‚ ì§œ" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
    elif "ì¼ì" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["ì¼ì"])
    else:
        raise ValueError(f"PRED ë‚ ì§œ ì»¬ëŸ¼(ë‚ ì§œ/ì¼ì) ì—†ìŒ: {path}")
    # ì˜ˆì¸¡ìˆ˜ëŸ‰ ì •ê·œí™”
    if "ì˜ˆì¸¡ìˆ˜ëŸ‰" not in df.columns:
        for c in ["pred", "ì˜ˆì¸¡", "prediction", "ì˜ˆì¸¡(ì‹ )"]:
            if c in df.columns:
                df["ì˜ˆì¸¡ìˆ˜ëŸ‰"] = df[c]
                break
        if "ì˜ˆì¸¡ìˆ˜ëŸ‰" not in df.columns:
            raise ValueError(f"PRED ì˜ˆì¸¡ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì—†ìŒ: {path}")
    # ìƒí’ˆëª… ë³´ì •
    if "ìƒí’ˆëª…" not in df.columns:
        for c in ["product_name", "ìƒí’ˆ"]:
            if c in df.columns:
                df["ìƒí’ˆëª…"] = df[c]
                break
    # âœ… ë¡œê·¸ ìŠ¤ì¼€ì¼ ë³µì› (ë‹¨, ì‹¤ì œë¡œ log ê°’ì¼ ë•Œë§Œ ë³µì›)
    if _looks_log_scale(df, store_name) or ("log" in model_name.lower()):
        # í‰ê· ì´ë‚˜ ìµœëŒ€ê°’ì´ log ë²”ìœ„(<=20) ì•ˆì¼ ë•Œë§Œ expm1 ìˆ˜í–‰
        if df["ì˜ˆì¸¡ìˆ˜ëŸ‰"].max() < 20 and df["ì˜ˆì¸¡ìˆ˜ëŸ‰"].mean() < 10:
            df["ì˜ˆì¸¡ìˆ˜ëŸ‰"] = np.expm1(np.clip(df["ì˜ˆì¸¡ìˆ˜ëŸ‰"].astype(float), a_min=-20, a_max=None))
    return df

def align_common_dates(pos_df: pd.DataFrame, pred_df: pd.DataFrame):
    common = sorted(set(pos_df["ì¼ì"]) & set(pred_df["ë‚ ì§œ"]))
    return (
        pos_df[pos_df["ì¼ì"].isin(common)].copy(),
        pred_df[pred_df["ë‚ ì§œ"].isin(common)].copy(),
    )

def normalize_grain_pos(df: pd.DataFrame) -> pd.DataFrame:
    cols = [c for c in ["ìƒí’ˆëª…"] if c in df.columns]
    return df.groupby(["ì¼ì"] + cols, as_index=False)["ìˆ˜ëŸ‰"].sum()

def normalize_grain_pred(df: pd.DataFrame) -> pd.DataFrame:
    cols = [c for c in ["ìƒí’ˆëª…"] if c in df.columns]
    out = df.groupby(["ë‚ ì§œ"] + cols, as_index=False)["ì˜ˆì¸¡ìˆ˜ëŸ‰"].sum()
    out["ì˜ˆì¸¡ìˆ˜ëŸ‰"] = out["ì˜ˆì¸¡ìˆ˜ëŸ‰"].clip(lower=0)  # ìŒìˆ˜ ë°©ì§€
    return out

def r2_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    if len(y_true) == 0:
        return np.nan
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    return 1 - ss_res / ss_tot if ss_tot != 0 else np.nan

def r2_weighted_by_sales(df: pd.DataFrame) -> float:
    """ìƒí’ˆë³„ RÂ² ê³„ì‚° í›„, ê° ìƒí’ˆì˜ ì‹¤ì œíŒë§¤ëŸ‰ í•©ê³„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ê°€ì¤‘ í‰ê· """
    if "ìƒí’ˆëª…" not in df.columns:
        return np.nan
    parts, weights = [], []
    for _, g in df.groupby("ìƒí’ˆëª…"):
        r2 = r2_score(g["ì‹¤ì œíŒë§¤ëŸ‰"], g["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"])
        w = float(g["ì‹¤ì œíŒë§¤ëŸ‰"].sum())
        if not np.isnan(r2) and w > 0:
            parts.append(r2)
            weights.append(w)
    if not parts:
        return np.nan
    return float(np.average(parts, weights=weights))

def filter_sparse_items_for_metric(df: pd.DataFrame, min_days: int = 3) -> pd.DataFrame:
    """ì§€í‘œ ê³„ì‚°ì—ì„œ ìµœì†Œ ì¼ìˆ˜ ë¯¸ë§Œ SKU ì œì™¸(í‘œì‹œëŠ” ê·¸ëŒ€ë¡œ)"""
    if "ìƒí’ˆëª…" not in df.columns:
        return df
    days = df.groupby("ìƒí’ˆëª…")["ë‚ ì§œ"].nunique()
    keep = days[days >= min_days].index
    return df[df["ìƒí’ˆëª…"].isin(keep)]

def to_kor_date(d: pd.Timestamp) -> str:
    return d.strftime("%y-%m-%d")

# -----------------------------
# ìŠ¤íƒ€ì¼
# -----------------------------

st.markdown(
    """
    <style>
    /* ===== ë°°ê²½ì„ ë² ì´ì§€ í†¤ìœ¼ë¡œ ===== */
    .stApp, .stApp header { background: #FFFFFF !important; }
    .stAppViewContainer, .main, .block-container { background: #FFFFFF !important; }

    /* ì¹´ë“œ / í‘œ ì˜ì—­ ê°™ì€ ë³´ì¡° ë°°ê²½ */
     .card, .stDataFrame, .stTable, .stMarkdown, .stSelectbox, .stDateInput, .stTextInput {
        background: #FFFFFF !important;   /* í•„ìš”ì‹œ #FAF5ECë¡œ ì‚´ì§ í†¤ ì¤„ ìˆ˜ë„ ìˆìŒ */
    }
    .card { border: 1px solid #EDEDED !important; }

    /* ì œëª©ë°”ëŠ” ì‚´ì§ ì§„í•œ ë² ì´ì§€ */
    .title-bar {
        background: #F2E7D8; 
        padding: 10px 14px; 
        border-radius: 10px;
    }

    /* í…ìŠ¤íŠ¸ ìƒ‰ */
    html, body {
        color: #2B2B2B !important;
    }

    /* ë²„íŠ¼(ë‹¤ìš´ë¡œë“œ í¬í•¨) í…Œë‘ë¦¬/í˜¸ë²„ */
    .stButton > button, .stDownloadButton > button {
        border: 2px solid #CBB8A0 !important;
        color: #2B2B2B !important;
        background: #FAF5EC !important;
        border-radius: 8px;
    }
    .stButton > button:hover, .stDownloadButton > button:hover {
        background: #F2E7D8 !important;
        border-color: #BDA78C !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.markdown(
    """
    <style>
    /* ì œëª© ë°” í¬ê¸° ì¦ê°€: 28px -> 40px */
    .title-bar {font-size:40px; font-weight:700; margin-bottom:18px;}
    
    /* ì¹´ë“œ ë°°ê²½ ìŠ¤íƒ€ì¼ ìœ ì§€ */
    .card {background:#fff; border-radius:12px; padding:12px 14px; border:1px solid #eee;}
    
    /* ë®¤íŠ¸ëœ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ìœ ì§€ */
    .muted {color:#666;}
    
    /* âœ… Streamlit ë³¸ë¬¸ í°íŠ¸ í¬ê¸° ëŒ€í­ ì¡°ì • (14px -> 17px) */
    html, body, .stText, .stMarkdown, .stLabel, .stSelectbox, .stTextInput, .stDateInput, .stButton > button {
        font-size: 17px !important; /* ê¸°ë³¸ 14pxì—ì„œ 17pxë¡œ ëŒ€í­ ì¦ê°€ */
    }
    
    /* ë¶€ì œëª© (h2, h3) í¬ê¸° ì¦ê°€ */
    h2 { font-size: 26px !important; } /* ê¸°ë³¸ 22pxì—ì„œ 26pxë¡œ ì¦ê°€ */
    h3 { font-size: 22px !important; } /* ê¸°ë³¸ 18pxì—ì„œ 22pxë¡œ ì¦ê°€ */

    /* ë°ì´í„°í”„ë ˆì„ í—¤ë”ì™€ ë‚´ìš© í¬ê¸° ì¡°ì • */
    .stDataFrame, .stTable {
        font-size: 16px !important; /* í‘œ ë‚´ë¶€ í°íŠ¸ ì¡°ì • */
    }
    
    /* ìº¡ì…˜(caption) í…ìŠ¤íŠ¸ í¬ê¸° ì¦ê°€ */
    .stCaption {
        font-size: 15px !important; /* ê¸°ë³¸ 12pxì—ì„œ 15pxë¡œ ì¦ê°€ */
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.markdown('<div class="title-bar">ğŸ© Randy\'s Donuts Â· ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ìˆ˜ìš”ì˜ˆì¸¡ ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)

tab_names = list(FILES.keys())
tabs = st.tabs(tab_names)

# ====== (ì¶”ê°€) ëª¨ë¸ ë¡œë“œ/í”¼ì²˜/ì˜ˆì¸¡ ìœ í‹¸ ======
import joblib
from pathlib import Path

MODEL_DIR = Path(BASE_DIR) / "models"
MODEL_DIR.mkdir(parents=True, exist_ok=True)

# log1pë¡œ í•™ìŠµí•œ ì§€ì ì€ True (ì˜ˆ: ê´‘ì•ˆë¦¬, ì—°ë‚¨)
STORE_LOG_TARGET = {
    "ì œì£¼ì• ì›”ì ": False,          # HGBR(.pkl)
    "ìˆ˜ì›íƒ€ì„ë¹Œë¦¬ì§€ì ": False,     # CatBoost(.cbm)
    "ì—°ë‚¨ì ": True,               # CatBoost log1p(.cbm)
    "ë¶€ì‚°ê´‘ì•ˆë¦¬ì ": True,          # CatBoost log1p(.cbm)
}

# ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ëª… ë§¤í•‘ (íŒŒì¼ëª…/í™•ì¥ì ì§€ê¸ˆ í´ë”ì™€ ì •í™•íˆ ë§ì¶”ì„¸ìš”)
def _assets_paths(store: str):
    key = {
        # ì œì£¼ì• ì›”ì ì€ í”¼ì²˜ íŒŒì¼ëª…ì´ ì£¼ì–´ì¡Œìœ¼ë‚˜, ì‹¤ì œë¡œ íŒŒì¼ì´ ì—†ì„ ê²½ìš°ë„ Noneìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€
        "ì œì£¼ì• ì›”ì ": ("aewol_hgbr_pipeline.skops", None, None),        # (model, features.pkl, categ.pkl)
        "ìˆ˜ì›íƒ€ì„ë¹Œë¦¬ì§€ì ": ("suwon_catboost.cbm", None, None),
        "ì—°ë‚¨ì ": ("yeonnam_catboost.cbm", None, None),
        "ë¶€ì‚°ê´‘ì•ˆë¦¬ì ": ("gwangan_catboost.cbm", None, None),
    }[store]
    m, f, c = key
    
    # âœ… ìˆ˜ì •: Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ Path ê°ì²´ë¥¼ ìƒì„±í•˜ê³ , Noneì¸ ê²½ìš° Noneì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
    model_path = MODEL_DIR / m
    feat_path = MODEL_DIR / f if f else None  
    catcols_path = MODEL_DIR / c if c else None

    # ìˆ˜ì •ëœ ë°˜í™˜
    return (model_path, feat_path, catcols_path)

def _expected_catboost_feature_names(model):
    # 1ìˆœìœ„: ëª¨ë¸ì´ ê¸°ì–µí•˜ëŠ” í”¼ì²˜ ì´ë¦„
    names = getattr(model, "feature_names_", None)
    if names and len(names) > 0:
        return list(names)
    # 2ìˆœìœ„: ì¤‘ìš”ë„ í…Œì´ë¸”ì—ì„œ ì¶”ì¶œ (ë²„ì „ì— ë”°ë¼ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¦„)
    try:
        fi = model.get_feature_importance(prettified=True)
        col = "Feature Id" if "Feature Id" in fi.columns else ("Feature" if "Feature" in fi.columns else None)
        if col:
            names = [str(x) for x in fi[col].tolist()]
            if len(names) > 0:
                return names
    except Exception:
        pass
    return None  # ëª» êµ¬í–ˆìœ¼ë©´ None
        

def _align_X_to_catboost(model, X: pd.DataFrame) -> pd.DataFrame:
    exp = _expected_catboost_feature_names(model)
    if not exp:
        # ì•ˆì „ì¥ì¹˜: ì´ë¦„ì„ ëª» êµ¬í•˜ë©´ ë°”ë¡œ ì‹¤íŒ¨ì‹œì¼œ ì›ì¸ íŒŒì•…
        missing = "ëª¨ë¸ì— ì €ì¥ëœ feature_names_ê°€ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ì‹œ feature_names ì €ì¥ ì˜µì…˜ì„ í™•ì¸í•˜ì„¸ìš”."
        raise RuntimeError(missing)

    # 1) ëˆ„ë½ëœ ì—´ì€ 0ìœ¼ë¡œ ì¶”ê°€
    for c in exp:
        if c not in X.columns:
            X[c] = 0

    # 2) ì—¬ë¶„ ì—´ ì œê±° + ìˆœì„œ ì¼ì¹˜
    X = X[[c for c in exp]]

    # 3) dtype ì •ë¦¬: ë²”ì£¼í˜• ê°€ëŠ¥ì„±ì´ ìˆëŠ” object/boolì€ ë¬¸ìì—´, datetimeì€ ë¬¸ìì—´ë¡œ
    for c in X.columns:
        if pd.api.types.is_datetime64_any_dtype(X[c]):
            X[c] = pd.to_datetime(X[c]).dt.strftime("%Y-%m-%d")
        elif pd.api.types.is_bool_dtype(X[c]) or pd.api.types.is_object_dtype(X[c]):
            X[c] = X[c].astype(str)

    return X

def load_model_for_store(store: str):
    model_path, _, _ = _assets_paths(store)
    kind = FILES[store]["pred_kind"].lower()
    if "hgbr" in kind:
        return _load_hgbr_pipeline(model_path), None, []
    else:
        return _load_catboost_model(model_path), None, []


# í•™ìŠµ ë…¸íŠ¸ë¶ê³¼ ë™ì¼ í”¼ì²˜ ì „ì²˜ë¦¬ë¥¼ ì—¬ê¸°ì— ë°˜ì˜í•˜ì„¸ìš”(ê°„ë‹¨ ê¸°ë³¸í˜• ì œê³µ)
def _base_features(df: pd.DataFrame):
    out = df.copy()
    out["dow"] = pd.to_datetime(out["ë‚ ì§œ"]).dt.weekday
    # ìˆ˜ì¹˜ ê²°ì¸¡ ë©”ìš°ê¸°
    num_cols = out.select_dtypes(include=[np.number]).columns
    out[num_cols] = out[num_cols].fillna(out[num_cols].median())
    return out

def make_features(store: str, X: pd.DataFrame) -> pd.DataFrame:
    """
    CatBoost ì…ë ¥ìš© í”¼ì²˜ ìƒì„±:
      - ë‚ ì§œ íŒŒìƒ: month / day / week
      - datetime â†’ ë¬¸ìì—´(YYYY-MM-DD) ë˜ëŠ” ì œê±°
      - object/bool â†’ ë¬¸ìì—´ë¡œ í†µì¼
      - ìˆ˜ì¹˜ ê²°ì¸¡ â†’ ì¤‘ì•™ê°’ ëŒ€ì²´
    â€» HGBR ë¶„ê¸°/ì›í•« ë“±ì€ ì´ í•¨ìˆ˜ì—ì„œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    out = X.copy()

    # ë‚ ì§œ íŒŒìƒ(ìˆì„ ë•Œë§Œ) + ë‚ ì§œ ì»¬ëŸ¼ ì œê±°
    if "ë‚ ì§œ" in out.columns:
        d = pd.to_datetime(out["ë‚ ì§œ"])
        out["month"] = d.dt.month.astype(int)
        out["day"]   = d.dt.day.astype(int)
        out["week"]  = d.dt.isocalendar().week.astype(int)
        out = out.drop(columns=["ë‚ ì§œ"], errors="ignore")

    # dtype ì •ë¦¬
    for c in out.columns:
        if pd.api.types.is_datetime64_any_dtype(out[c]):
            # ë‚¨ì•„ ìˆëŠ” datetimeì´ ìˆë‹¤ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
            out[c] = pd.to_datetime(out[c]).dt.strftime("%Y-%m-%d")
        elif pd.api.types.is_bool_dtype(out[c]) or pd.api.types.is_object_dtype(out[c]):
            # CatBoost í˜¸í™˜ì„ ìœ„í•´ ë²”ì£¼í˜•/ë¬¸ìì—´ì€ ì „ë¶€ strë¡œ
            out[c] = out[c].astype(str)

    # ìˆ˜ì¹˜ ê²°ì¸¡ ì¹˜í™˜(ì¤‘ì•™ê°’)
    num_cols = out.select_dtypes(include=[np.number]).columns
    if len(num_cols):
        out[num_cols] = out[num_cols].fillna(out[num_cols].median())

    return out

def make_features_for_catboost(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    if "ë‚ ì§œ" in out.columns:
        d = pd.to_datetime(out["ë‚ ì§œ"])
        out["month"] = d.dt.month.astype(int)
        out["day"]   = d.dt.day.astype(int)
        out["week"]  = d.dt.isocalendar().week.astype(int)
        out = out.drop(columns=["ë‚ ì§œ"], errors="ignore")
    # dtype ì •ë¦¬
    for c in out.columns:
        if pd.api.types.is_datetime64_any_dtype(out[c]):
            out[c] = pd.to_datetime(out[c]).dt.strftime("%Y-%m-%d")
        elif pd.api.types.is_bool_dtype(out[c]) or pd.api.types.is_object_dtype(out[c]):
            out[c] = out[c].astype(str)
    num_cols = out.select_dtypes(include=[np.number]).columns
    if len(num_cols):
        out[num_cols] = out[num_cols].fillna(out[num_cols].median())
    return out

# === ì œì£¼ì• ì›”(HGBR)ìš©: í•™ìŠµ ë•Œ ì“°ë˜ ì»¬ëŸ¼ì„ ì •í™•íˆ ë§Œë“¤ì–´ì¤Œ
def make_hgbr_inputs_from_grid(df: pd.DataFrame) -> pd.DataFrame:
    """
    future_grid(ë‚ ì§œ, ìƒí’ˆëª…) -> HGBR íŒŒì´í”„ë¼ì¸ì´ ê¸°ëŒ€í•˜ëŠ” ì›ì‹œ í”¼ì²˜ í”„ë ˆì„
    - cat: ['ìƒí’ˆëª…','day']  (dayëŠ” ìš”ì¼ì˜ë¬¸ëª…ìœ¼ë¡œ ìƒì„±)
    - num: ['month','is_holiday','is_holiday_window','is_pre_holiday_window',
            'is_post_holiday_window','holiday_weight','temp_max','precip','event_any',
            'event_closing_50','event_lucky_box','event_picnic_mat','event_world_donut_day',
            'event_closing_50_days_since_start','event_lucky_box_days_since_start',
            'event_picnic_mat_days_since_start','event_world_donut_day_days_since_start']
    """
    out = df.copy()

    # ë‚ ì§œ íŒŒìƒ
    d = pd.to_datetime(out["ë‚ ì§œ"])
    # í•™ìŠµ ë•Œ dayê°€ ìš”ì¼ ì´ë¦„ì´ì—ˆë‹¤ë©´ â†’ ì˜ì–´ ìš”ì¼ëª…ìœ¼ë¡œ ìƒì„± (Mon..Sun)
    out["day"] = d.dt.day_name()  # e.g., 'Monday', 'Tuesday', ...
    out["month"] = d.dt.month.astype(int)

    # í•„ìˆ˜ ì»¬ëŸ¼ë“¤(ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€)
    needed_zero = [
        "is_holiday","is_holiday_window","is_pre_holiday_window","is_post_holiday_window",
        "holiday_weight","temp_max","precip","event_any",
        "event_closing_50","event_lucky_box","event_picnic_mat","event_world_donut_day",
        "event_closing_50_days_since_start","event_lucky_box_days_since_start",
        "event_picnic_mat_days_since_start","event_world_donut_day_days_since_start",
    ]
    for c in needed_zero:
        if c not in out.columns:
            out[c] = 0

    # dtype ì •ë¦¬: ë²”ì£¼í˜•ì€ ë¬¸ìì—´, ìˆ˜ì¹˜ëŠ” ìˆ«ì
    out["ìƒí’ˆëª…"] = out["ìƒí’ˆëª…"].astype(str).str.strip()
    out["day"]   = out["day"].astype(str).str.strip()

    num_cols = [
        "month","is_holiday","is_holiday_window","is_pre_holiday_window","is_post_holiday_window",
        "holiday_weight","temp_max","precip","event_any",
        "event_closing_50","event_lucky_box","event_picnic_mat","event_world_donut_day",
        "event_closing_50_days_since_start","event_lucky_box_days_since_start",
        "event_picnic_mat_days_since_start","event_world_donut_day_days_since_start",
    ]
    for c in num_cols:
        out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0)

    # íŒŒì´í”„ë¼ì¸ì— ë„˜ê¸¸ ì»¬ëŸ¼ ìˆœì„œ(ì´ ìˆœì„œë¡œ ë„˜ê¸°ë©´ ì•ˆì „)
    cat_cols = ["ìƒí’ˆëª…","day"]
    cols = cat_cols + num_cols
    return out[cols]

def build_future_grid(base_date: pd.Timestamp, horizon: int, df_train_like: pd.DataFrame):
    """ê¸°ì¤€ì¼ ë‹¤ìŒë‚ ë¶€í„° horizonì¼ê¹Œì§€ ë‚ ì§œÃ—ìƒí’ˆ ê·¸ë¦¬ë“œ ìƒì„±"""
    base_date = pd.to_datetime(base_date)
    dates = pd.date_range(base_date + pd.Timedelta(days=1),
                          base_date + pd.Timedelta(days=horizon), freq="D")
    prods = (df_train_like["ìƒí’ˆëª…"].astype("category").cat.categories
             if pd.api.types.is_categorical_dtype(df_train_like["ìƒí’ˆëª…"])
             else sorted(df_train_like["ìƒí’ˆëª…"].unique()))
    grid = (
        pd.DataFrame({"ë‚ ì§œ": dates}).assign(key=1)
          .merge(pd.DataFrame({"ìƒí’ˆëª…": prods, "key":1}), on="key", how="inner")
          .drop(columns="key").sort_values(["ë‚ ì§œ","ìƒí’ˆëª…"]).reset_index(drop=True)
    )
    return grid

def predict_next_week(store: str, base_date: pd.Timestamp, train_like_df: pd.DataFrame, horizon: int = 7) -> pd.DataFrame:
    model, _, _ = load_model_for_store(store)
    log_target = STORE_LOG_TARGET.get(store, False)

    future_grid = build_future_grid(base_date, horizon, train_like_df)

    if "hgbr" in FILES[store]["pred_kind"].lower():
        X = make_hgbr_inputs_from_grid(future_grid.copy())
        yhat = np.asarray(model.predict(X), float)
    else:
        X = make_features_for_catboost(future_grid.copy())
        X = _align_X_to_catboost(model, X)
        yhat = np.asarray(model.predict(X), float)

    if log_target:
        yhat = np.expm1(yhat)
    yhat = np.clip(yhat, 0, None)

    out = future_grid.copy()
    out["ì˜ˆì¸¡ìˆ˜ëŸ‰"] = yhat
    return out[["ë‚ ì§œ","ìƒí’ˆëª…","ì˜ˆì¸¡ìˆ˜ëŸ‰"]]

# -----------------------------
# íƒ­ ë Œë”ë§
# -----------------------------
for tab_name, tab in zip(tab_names, tabs):
    with tab:
        conf = FILES[tab_name]
        model_name = conf.get("pred_kind", "")
        colL, colR = st.columns([1.45, 1.0], gap="large")

        # ë°ì´í„° ë¡œë“œ ë° ê³µí†µì¼ì ì •ë ¬
        pos = load_pos(conf["pos"])
        pred = load_pred(conf["pred"], store_name=tab_name, model_name=model_name)
        pos, pred = align_common_dates(pos, pred)

        st.markdown(f"**ì§€ì :** {tab_name}  Â·  ëª¨ë¸: {model_name}")

        # ----------------- ì¢Œ: ê²€ì¦ íŒ¨ë„ -----------------
        with colL:
            st.subheader("ì¡°íšŒê¸°ê°„ Â· ìƒí’ˆì½”ë“œ / ê²€ì¦")

            c1, c2, c3, c4, c5 = st.columns([0.6, 0.6, 0.7, 1.2, 0.5])
            min_d = pos["ì¼ì"].min()
            max_d = pos["ì¼ì"].max()

            from_d = c1.date_input(
                "ì¡°íšŒ ì‹œì‘ì¼",
                min_d.date() if pd.notna(min_d) else datetime.today().date(),
                key=f"{tab_name}_from_date",
            )
            to_d = c2.date_input(
                "ì¡°íšŒ ì¢…ë£Œì¼",
                max_d.date() if pd.notna(max_d) else datetime.today().date(),
                key=f"{tab_name}_to_date",
            )

            item_list = (
                sorted(pos["ìƒí’ˆëª…"].dropna().unique().tolist())
                if "ìƒí’ˆëª…" in pos.columns
                else ["(ì „ì²´)"]
            )
            item_sel = c3.selectbox(
                "ìƒí’ˆëª…",
                options=["(ì „ì²´)"] + item_list,
                index=0,
                key=f"{tab_name}_item_sel",
            )
            item_query = c4.text_input(
                "ìƒí’ˆì½”ë“œ/ëª… ê²€ìƒ‰",
                "",
                placeholder="ìƒí’ˆëª… ì¼ë¶€ ë˜ëŠ” ì½”ë“œ ì…ë ¥",
                key=f"{tab_name}_item_query",
            )
            c5.button("ì¡°íšŒ", use_container_width=True, key=f"{tab_name}_left_query_btn")

            _from = pd.Timestamp(from_d)
            _to = pd.Timestamp(to_d) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
            pos_q = pos[(pos["ì¼ì"] >= _from) & (pos["ì¼ì"] <= _to)].copy()
            pred_q = pred[(pred["ë‚ ì§œ"] >= _from) & (pred["ë‚ ì§œ"] <= _to)].copy()

            # ì„ íƒ í•„í„°
            if item_sel != "(ì „ì²´)" and "ìƒí’ˆëª…" in pos_q.columns:
                pos_q = pos_q[pos_q["ìƒí’ˆëª…"] == item_sel]
                pred_q = pred_q[pred_q["ìƒí’ˆëª…"] == item_sel]
            if item_query.strip():
                key = item_query.strip()
                if "ìƒí’ˆëª…" in pos_q.columns:
                    mpos = pos_q["ìƒí’ˆëª…"].astype(str).str.contains(key, case=False, na=False)
                else:
                    mpos = pd.Series([False] * len(pos_q), index=pos_q.index)
                if "ìƒí’ˆì½”ë“œ" in pos_q.columns:
                    mpos |= pos_q["ìƒí’ˆì½”ë“œ"].astype(str).str.contains(key, case=False, na=False)
                pos_q = pos_q[mpos] if len(pos_q) else pos_q

            # ===================== ì •ê·œí™” Â· ì§‘ê³„ Â· ë³‘í•© (êµì²´ ë¸”ë¡ ì‹œì‘) =====================
            # í‘œì‹œ/í‚¤ ë¶„ë¦¬: ë§¤ì¹­ì€ key(ì†Œë¬¸ì/íŠ¸ë¦¼), í‘œì‹œëŠ” display ìœ ì§€
            if "ìƒí’ˆëª…" in pos_q.columns:
                pos_q["ìƒí’ˆëª…_display"] = pos_q["ìƒí’ˆëª…"].astype(str)
                pos_q["ìƒí’ˆëª…_key"] = pos_q["ìƒí’ˆëª…_display"].str.strip().str.lower()
            if "ìƒí’ˆëª…" in pred_q.columns:
                pred_q["ìƒí’ˆëª…_key"] = pred_q["ìƒí’ˆëª…"].astype(str).str.strip().str.lower()

            # POSì— ì¡´ì¬í•˜ëŠ” SKUë§Œ ì˜ˆì¸¡ì—ì„œ ìœ ì§€
            if "ìƒí’ˆëª…_key" in pos_q.columns and "ìƒí’ˆëª…_key" in pred_q.columns:
                valid_items = set(pos_q["ìƒí’ˆëª…_key"])
                pred_q = pred_q[pred_q["ìƒí’ˆëª…_key"].isin(valid_items)]

            # ê·¸ë ˆì¸ ì •ê·œí™” (ì¼ìÃ—ìƒí’ˆ)
            pos_day  = pos_q.groupby(["ì¼ì", "ìƒí’ˆëª…_key", "ìƒí’ˆëª…_display"], as_index=False)["ìˆ˜ëŸ‰"].sum()
            pred_day = pred_q.groupby(["ë‚ ì§œ", "ìƒí’ˆëª…_key"],                         as_index=False)["ì˜ˆì¸¡ìˆ˜ëŸ‰"].sum()

            # ìˆ«ìí˜• ê°•ì œ ë³€í™˜(í˜¼ì… ë°©ì§€)
            pos_day["ìˆ˜ëŸ‰"]      = pd.to_numeric(pos_day["ìˆ˜ëŸ‰"], errors="coerce")
            pred_day["ì˜ˆì¸¡ìˆ˜ëŸ‰"] = pd.to_numeric(pred_day["ì˜ˆì¸¡ìˆ˜ëŸ‰"], errors="coerce")

            # ë³‘í•© (ì¼ìâ†’ë‚ ì§œë¡œ ë§ì¶¤)
            merged = pd.merge(
                pos_day.rename(columns={"ì¼ì": "ë‚ ì§œ"}),
                pred_day,
                on=["ë‚ ì§œ", "ìƒí’ˆëª…_key"],
                how="inner",
            )

            # í‘œì‹œìš© ìƒí’ˆëª… ë³µì› í›„ í‚¤ ì»¬ëŸ¼ ì œê±°
            merged["ìƒí’ˆëª…"] = merged["ìƒí’ˆëª…_display"]
            merged = merged.drop(columns=["ìƒí’ˆëª…_display", "ìƒí’ˆëª…_key"])

            # ê³¼ê±°ì˜ˆì¸¡(ì˜µì…˜) í•©ì¹˜ê¸°
            if "ì£¼ë¬¸ëŸ‰_ceil" in pred_q.columns:
                old = pred_q.groupby(["ë‚ ì§œ", "ìƒí’ˆëª…_key"], as_index=False)["ì£¼ë¬¸ëŸ‰_ceil"].sum()
                name_map = pos_day[["ìƒí’ˆëª…_key", "ìƒí’ˆëª…_display"]].drop_duplicates()
                old = old.merge(name_map, on="ìƒí’ˆëª…_key", how="left")
                old["ìƒí’ˆëª…"] = old["ìƒí’ˆëª…_display"]
                old = old.drop(columns=["ìƒí’ˆëª…_display", "ìƒí’ˆëª…_key"])
                merged = pd.merge(merged, old, on=["ë‚ ì§œ", "ìƒí’ˆëª…"], how="left").rename(
                    columns={"ì£¼ë¬¸ëŸ‰_ceil": "ê³¼ê±°ìˆ˜ìš”ì˜ˆì¸¡"}
                )
            else:
                merged["ê³¼ê±°ìˆ˜ìš”ì˜ˆì¸¡"] = np.nan

            # í‘œì¤€ ì»¬ëŸ¼ëª… ì •ë¦¬
            merged = merged.rename(columns={"ìˆ˜ëŸ‰": "ì‹¤ì œíŒë§¤ëŸ‰", "ì˜ˆì¸¡ìˆ˜ëŸ‰": "eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"})

            # ìˆ«ìí˜• ê°•ì œ ë³€í™˜ + ìœ í•œê°’ë§Œ ìœ ì§€
            merged["ì‹¤ì œíŒë§¤ëŸ‰"]    = pd.to_numeric(merged["ì‹¤ì œíŒë§¤ëŸ‰"], errors="coerce")
            merged["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"] = pd.to_numeric(merged["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"], errors="coerce")
            is_finite = np.isfinite(merged["ì‹¤ì œíŒë§¤ëŸ‰"]) & np.isfinite(merged["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"])
            merged = merged[is_finite].copy()
            # ===================== ì •ê·œí™” Â· ì§‘ê³„ Â· ë³‘í•© (êµì²´ ë¸”ë¡ ë) =====================

            # ===== ë³´ì • (íƒ1ë¡œ ì„¤ì •í•´ì„œ ì‚¬ìš©) =====
            scale_mode = "SKUë³„ í•© ë§ì¶¤"   # "ì „ì²´í•© ë§ì¶¤" / "ì—†ìŒ"

            if scale_mode == "ì „ì²´í•© ë§ì¶¤":
                pred_sum = merged["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"].sum()
                if pred_sum > 0:
                    merged["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"] *= (merged["ì‹¤ì œíŒë§¤ëŸ‰"].sum() / pred_sum)

            elif scale_mode == "SKUë³„ í•© ë§ì¶¤" and "ìƒí’ˆëª…" in merged.columns:
                grp = merged.groupby("ìƒí’ˆëª…")[["ì‹¤ì œíŒë§¤ëŸ‰", "eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"]].sum()
                ratio = (grp["ì‹¤ì œíŒë§¤ëŸ‰"] / grp["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"]).replace([np.inf, -np.inf], np.nan).fillna(1.0)
                merged = merged.merge(ratio.rename("item_scale"), left_on="ìƒí’ˆëª…", right_index=True, how="left")
                merged["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"] *= merged["item_scale"]
                merged.drop(columns=["item_scale"], inplace=True)
            # else: ì—†ìŒ

            # ì˜¤ì°¨
            merged["ì˜¤ì°¨"] = (merged["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"] - merged["ì‹¤ì œíŒë§¤ëŸ‰"]).round(0)

            # ---- ì •í™•ë„ ê³„ì‚°
            metric_df = filter_sparse_items_for_metric(merged, min_days=3)
            R2_weighted = r2_weighted_by_sales(metric_df)
            daily_total = merged.groupby("ë‚ ì§œ", as_index=False)[["ì‹¤ì œíŒë§¤ëŸ‰", "eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"]].sum()
            R2_daily = r2_score(daily_total["ì‹¤ì œíŒë§¤ëŸ‰"].values, daily_total["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"].values)

            r2_weighted_txt = f"{R2_weighted*100:0.2f}%" if pd.notna(R2_weighted) else "N/A"
            r2_daily_txt    = f"{R2_daily*100:0.2f}%"    if pd.notna(R2_daily)    else "N/A"

            st.markdown(f"**ê²€ì¦ ê²°ê³¼** Â· SKUë³„ ê°€ì¤‘ RÂ²: **{r2_weighted_txt}** Â· ì¼ë³„ ì´í•© RÂ²: **{r2_daily_txt}**")

            if pd.notna(R2_weighted) and R2_weighted < -1.0:
                bad = metric_df.copy()
                bad["ì ˆëŒ€ì˜¤ì°¨"] = (bad["eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡"] - bad["ì‹¤ì œíŒë§¤ëŸ‰"]).abs()
                worst = bad.groupby("ìƒí’ˆëª…")["ì ˆëŒ€ì˜¤ì°¨"].sum().sort_values(ascending=False).head(5)
                st.warning(
                    "RÂ²ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ìŠµë‹ˆë‹¤. (ê°€ëŠ¥ ì›ì¸: ë¡œê·¸ ë¯¸ë³µì›, SKU ë¯¸ìŠ¤ë§¤ì¹˜, ë‹¨ìœ„ ë¶ˆì¼ì¹˜, í¬ì†Œ SKU)\n"
                    f"- ìµœë‹¤ ì˜¤ì°¨ SKU Top5: {', '.join(map(str, worst.index.tolist()))}\n"
                    "- ì˜ˆì¸¡ìˆ˜ëŸ‰ ì´ìƒì¹˜/ìŒìˆ˜ ì—¬ë¶€ì™€ ìƒí’ˆëª… ë§¤ì¹­ì„ í™•ì¸í•˜ì„¸ìš”."
                )

            # ---- ì°¨íŠ¸/í‘œ
            chart_day = merged.groupby("ë‚ ì§œ")[["ì‹¤ì œíŒë§¤ëŸ‰", "eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡", "ê³¼ê±°ìˆ˜ìš”ì˜ˆì¸¡"]].sum().reset_index().sort_values("ë‚ ì§œ")
            chart_day_display = chart_day.copy()
            chart_day_display["ë‚ ì§œ"] = chart_day_display["ë‚ ì§œ"].dt.strftime("%Y-%m-%d")
            st.line_chart(chart_day_display.set_index("ë‚ ì§œ")[["ì‹¤ì œíŒë§¤ëŸ‰", "eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡", "ê³¼ê±°ìˆ˜ìš”ì˜ˆì¸¡"]])

            table_day = merged.groupby("ë‚ ì§œ", as_index=False)[["ì‹¤ì œíŒë§¤ëŸ‰", "eì‹œí¬ ìˆ˜ìš”ì˜ˆì¸¡", "ì˜¤ì°¨"]].sum().sort_values("ë‚ ì§œ")
            table_day_display = table_day.copy()
            table_day_display.insert(0, "ë‚ ì§œ(yy-mm-dd)", table_day_display["ë‚ ì§œ"].apply(to_kor_date))
            table_day_display = table_day_display.drop(columns=["ë‚ ì§œ"])
            st.dataframe(table_day_display, use_container_width=True, height=260)

            st.markdown("**í•´ë‹¹ ê¸°ê°„ë™ì•ˆ ìˆ˜ìš”ì˜ˆì¸¡ ê²°ê³¼ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ ìš”ì¸**")
            st.markdown('<div class="card muted">1ìˆœìœ„: ìš”ì¼ Â· 2ìˆœìœ„: ë‚ ì”¨(ìµœê³ ê¸°ì˜¨)</div>', unsafe_allow_html=True)

        # ----------------- ìš°: ê¸°ì¤€ì¼ì 7ì¼ ì˜ˆì¸¡ -----------------
        with colR:
            st.subheader("ê¸°ì¤€ì¼ì Â· 7ì¼ ì˜ˆì¸¡")
            r1, r2 = st.columns([1.0, 0.3])
            base_date = r1.date_input(
                "ê¸°ì¤€ì¼ì",
                value=(pos["ì¼ì"].max().date() if len(pos) else datetime.today().date()),
                key=f"{tab_name}_right_base",
            )
            r2.write("")
            run_btn = st.button("ë‹¤ìŒì£¼ ì˜ˆì¸¡ ìƒì„±í•˜ê¸°", key=f"{tab_name}_run_model", use_container_width=True)

            # í•™ìŠµ ë•Œ ë³¸ SKU ëª©ë¡ ì¬í˜„ìš©: POSë¥¼ ì¼ìÃ—ìƒí’ˆ í•©ê³„ í˜•íƒœë¡œ
            if "ìƒí’ˆëª…" in pos.columns:
                train_like = (
                    pos.groupby(["ì¼ì","ìƒí’ˆëª…"], as_index=False)["ìˆ˜ëŸ‰"]
                    .sum().rename(columns={"ì¼ì":"ë‚ ì§œ"})
                )
            else:
                tmp = pos.groupby("ì¼ì", as_index=False)["ìˆ˜ëŸ‰"].sum().rename(columns={"ì¼ì":"ë‚ ì§œ"})
                tmp["ìƒí’ˆëª…"] = "(ì „ì²´)"
                train_like = tmp[["ë‚ ì§œ","ìƒí’ˆëª…"]].copy()

            if run_btn:
                try:
                    pred_out = predict_next_week(tab_name, pd.Timestamp(base_date), train_like, horizon=7)
                    fn = f"{tab_name}_next7_pred_{pd.Timestamp(base_date).strftime('%Y%m%d')}.csv"
                    csv_bytes = pred_out.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
                    
                    # ----------------------------------------------------
                    # âœ… ì˜ˆì¸¡ ì™„ë£Œ ë©”ì‹œì§€ ë° ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°•í™” ë¶€ë¶„ ì‹œì‘
                    # ----------------------------------------------------
                    
                    # 1. í°íŠ¸ í¬ê¸°ë¥¼ í‚¤ìš´ Success ë©”ì‹œì§€ ì¶œë ¥
                    st.markdown(
                        '<p style="font-size:20px; font-weight:bold; color:green;">ì˜ˆì¸¡ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ CSV ì €ì¥í•˜ì„¸ìš”.</p>',
                        unsafe_allow_html=True
                    )
                    
                    # 2. ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ CSS ì‚½ì…
                    st.markdown(
                        """
                        <style>
                        /* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í¬í•¨í•˜ëŠ” stDownloadButton ì»¨í…Œì´ë„ˆì˜ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
                        .stDownloadButton > button {
                            font-size: 18px !important; /* í°íŠ¸ í¬ê¸° ì¦ê°€ */
                            font-weight: bold !important; /* êµµê²Œ */
                            padding: 10px 20px !important; /* íŒ¨ë”© ì¦ê°€ë¡œ ë²„íŠ¼ í¬ê¸° í‚¤ìš°ê¸° */
                            
                            /* âœ… í…Œë‘ë¦¬ë¥¼ ëª…í™•í•œ íšŒìƒ‰ìœ¼ë¡œ ì„¤ì • */
                            border: 2px solid #ccc !important; 
                            
                            /* ë°°ê²½ìƒ‰ì€ íˆ¬ëª… ìœ ì§€ (Streamlit ê¸°ë³¸ê°’) */
                            background-color: transparent !important;
                            
                            /* í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ ê²€ì • ê³„ì—´ë¡œ ì„¤ì •í•˜ì—¬ ì˜ ë³´ì´ë„ë¡ í•¨ */
                            color: #333333 !important; 
                            border-radius: 8px;
                        }
                        </style>
                        """,
                        unsafe_allow_html=True
                    )
                    
                    # 3. ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶œë ¥
                    st.download_button(
                        "ë‹¤ìŒì£¼ ì˜ˆì¸¡ CSV ë‹¤ìš´ë¡œë“œ", 
                        data=csv_bytes, 
                        file_name=fn, 
                        mime="text/csv"
                    )
                    
                    # ----------------------------------------------------
                    # âœ… ìŠ¤íƒ€ì¼ ê°•í™” ë¶€ë¶„ ì¢…ë£Œ
                    # ----------------------------------------------------

                    show_cols = ["ë‚ ì§œ","ìƒí’ˆëª…","ì˜ˆì¸¡ìˆ˜ëŸ‰"] if "ìƒí’ˆëª…" in pred_out.columns else ["ë‚ ì§œ","ì˜ˆì¸¡ìˆ˜ëŸ‰"]
                    st.dataframe(pred_out[show_cols].sort_values(["ë‚ ì§œ","ìƒí’ˆëª…"] if "ìƒí’ˆëª…" in show_cols else ["ë‚ ì§œ"]),
                                 use_container_width=True, height=480)
                except Exception as e:
                    st.error(f"ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ({tab_name}): {type(e).__name__}: {e}")


            st.caption("â€» ë¡œì»¬ì— ì €ì¥ëœ ëª¨ë¸/í”¼ì²˜ë¥¼ ì‚¬ìš©í•´ ê¸°ì¤€ì¼ ë‹¤ìŒë‚ ë¶€í„° 7ì¼ ì˜ˆì¸¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")
